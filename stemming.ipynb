{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEMMING\n",
    "This is transforming words to their most basic form.  \n",
    "This includes removing prefixes and suffixes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PORTER'S STEMMER\n",
    "The output is not necessarily a word with meaning.  \n",
    "Only limited to English.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['running', 'jumps', 'happily', 'running', 'happily']\n",
      "Stemmed words: ['run', 'jump', 'happili', 'run', 'happili']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Create a Porter Stemmer instance\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Example words for stemming\n",
    "words = [\"running\", \"jumps\", \"happily\", \"running\", \"happily\"]\n",
    "\n",
    "# Apply stemming to each word\n",
    "stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
    "\n",
    "# Print the results\n",
    "print(\"Original words:\", words)\n",
    "print(\"Stemmed words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program  :  program\n",
      "programs  :  program\n",
      "programmer  :  programm\n",
      "programming  :  program\n",
      "programmers  :  programm\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\"]\n",
    "\n",
    "for w in words:\n",
    "\tprint(w, \" : \", ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programmers  :  programm\n",
      "program  :  program\n",
      "with  :  with\n",
      "programming  :  program\n",
      "languages  :  languag\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "sentence = \"Programmers program with programming languages\"\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "for w in words:\n",
    "\tprint(w, \" : \", ps.stem(w))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SNOWBALL STEMMER\n",
    "Also called Porter2 Stemmer.  \n",
    "Is multi-lingual and has greater computational speed than Porter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['running', 'jumped', 'happily', 'quickly', 'foxes']\n",
      "Stemmed words: ['run', 'jump', 'happili', 'quick', 'fox']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Choose a language for stemming, for example, English\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "# Example words to stem\n",
    "words_to_stem = ['running', 'jumped', 'happily', 'quickly', 'foxes']\n",
    "\n",
    "# Apply Snowball Stemmer\n",
    "stemmed_words = [stemmer.stem(word) for word in words_to_stem]\n",
    "\n",
    "# Print the results\n",
    "print(\"Original words:\", words_to_stem)\n",
    "print(\"Stemmed words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LANCASTER STEMMER\n",
    "Faster, dynamic and more aggressive.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['running', 'jumped', 'happily', 'quickly', 'foxes']\n",
      "Stemmed words: ['run', 'jump', 'happy', 'quick', 'fox']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "# Create a Lancaster Stemmer instance\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# Example words to stem\n",
    "words_to_stem = ['running', 'jumped', 'happily', 'quickly', 'foxes']\n",
    "\n",
    "# Apply Lancaster Stemmer\n",
    "stemmed_words = [stemmer.stem(word) for word in words_to_stem]\n",
    "\n",
    "# Print the results\n",
    "print(\"Original words:\", words_to_stem)\n",
    "print(\"Stemmed words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REGEXP STEMMER\n",
    "Uses regular expressions to identify and remove suffixes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: running\n",
      "Stemmed Word: runn\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "# Create a Regexp Stemmer with a custom rule\n",
    "custom_rule = r'ing$'\n",
    "regexp_stemmer = RegexpStemmer(custom_rule)\n",
    "\n",
    "# Apply the stemmer to a word\n",
    "word = 'running'\n",
    "stemmed_word = regexp_stemmer.stem(word)\n",
    "\n",
    "print(f'Original Word: {word}')\n",
    "print(f'Stemmed Word: {stemmed_word}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
